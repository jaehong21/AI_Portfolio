{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import unicodedata\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4_Deep learning_(1)과 대부분의 코드 및 흐름이 유사하므로, 코드에 대한 자세한 설명은 생략하고자 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2\n",
    "        \n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "    \n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else: \n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "    \n",
    "    lines = open('%s-%s.txt' % (lang1, lang2), encoding='utf-8').read().strip().split('\\n')\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "    \n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else: \n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "        \n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH and p[1].startswith(eng_prefixes)\n",
    "    # 만약 reverse=False면 p[0].starswith(eng_prefixes)\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    \n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    \n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 10599 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4345\n",
      "eng 2803\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        # what does .view(1, 1, -1) mean?\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    # Why append the EOS tokens for both input/output tensor sequence\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "teacher_forcing_ratio = 1\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion,\n",
    "          max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    \n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "    loss = 0\n",
    "    \n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "    \n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "    decoder_hidden = encoder_hidden \n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden= decoder(decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "        \n",
    "    loss.backward()\n",
    "    \n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "plot_losses = []\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "\n",
    "    print_loss_total = 0\n",
    "    plot_loss_total = 0\n",
    "    \n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    for iter in range(1, n_iters+1): \n",
    "        training_pair = training_pairs[iter-1]\n",
    "        input_tensor  = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        \n",
    "        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "        \n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 14s (- 17m 22s) (5000 6%) 2.7065\n",
      "2m 15s (- 14m 41s) (10000 13%) 2.0017\n",
      "3m 11s (- 12m 47s) (15000 20%) 1.6905\n",
      "4m 8s (- 11m 23s) (20000 26%) 1.4707\n",
      "5m 5s (- 10m 10s) (25000 33%) 1.2652\n",
      "6m 1s (- 9m 2s) (30000 40%) 1.1124\n",
      "6m 58s (- 7m 58s) (35000 46%) 0.9778\n",
      "7m 54s (- 6m 55s) (40000 53%) 0.8521\n",
      "8m 51s (- 5m 54s) (45000 60%) 0.7374\n",
      "9m 48s (- 4m 54s) (50000 66%) 0.6476\n",
      "10m 45s (- 3m 54s) (55000 73%) 0.5632\n",
      "11m 41s (- 2m 55s) (60000 80%) 0.4877\n",
      "12m 38s (- 1m 56s) (65000 86%) 0.4408\n",
      "13m 34s (- 0m 58s) (70000 93%) 0.3672\n",
      "14m 31s (- 0m 0s) (75000 100%) 0.3378\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder1 = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "trainIters(encoder1, decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "xdomain = np.arange(75000/100)\n",
    "xdomain += 1\n",
    "\n",
    "plt.plot(xdomain, plot_losses, marker='.', color='red')\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss of seq2seq\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> je suis desole de vous avoir fait attendre .\n",
      "= i am sorry to have kept you waiting .\n",
      "< i m sorry to have kept you waiting . <EOS>\n",
      "\n",
      "> ils sont dingues de jazz .\n",
      "= they are crazy about jazz .\n",
      "< they are crazy about jazz . <EOS>\n",
      "\n",
      "> je suis ravi que vous ayez souleve ca .\n",
      "= i m glad you brought that up .\n",
      "< i m glad you brought that up . <EOS>\n",
      "\n",
      "> ils sont de retour .\n",
      "= they re back .\n",
      "< they re back . <EOS>\n",
      "\n",
      "> je suis tout seul dans ce pays etranger .\n",
      "= i am all alone in a foreign country .\n",
      "< i am all alone in a foreign . <EOS>\n",
      "\n",
      "> je suis deja mariee .\n",
      "= i m already married .\n",
      "< i m already married . <EOS>\n",
      "\n",
      "> il est plein d ambition .\n",
      "= he is full of ambition .\n",
      "< he is full of energy . <EOS>\n",
      "\n",
      "> ils sont jaloux de nous .\n",
      "= they are jealous of us .\n",
      "< they are jealous of us . <EOS>\n",
      "\n",
      "> je suis fortune .\n",
      "= i m wealthy .\n",
      "< i m wealthy . <EOS>\n",
      "\n",
      "> nous tentons notre chance .\n",
      "= we re tempting fate .\n",
      "< we re having a blast . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "\n",
    "        # decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            # decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words # decoder_attentions[:di + 1]\n",
    "    \n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n",
    "        \n",
    "evaluateRandomly(encoder1, decoder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4_Deep learning_(1), (2)와 비교했을 때, 확실히 영어-프랑스어 번역기의 성능은 매우 우수하다. <br />\n",
    "여기에는 여러가지 이유가 있다고 생각된다. <br />\n",
    "1. 애초에, Pytorch 공식 사이트에서 제공하는 seq2seq 튜토리얼에서 영어-프랑스어 번역을 목적으로 하고 있다.\n",
    "2. 영어와 프랑스어는 어순 및 언어적으로 유사한 점이 많다.\n",
    "3. 한국어 데이터 셋은 필자가 전처리를 거친 것에 비해서, 영어-프랑스어 데이터셋은 이미 전처리가 간단한 문장으로 거친 상태이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>모델 저장</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder1, 'encoder(3).pt')\n",
    "torch.save(decoder1, 'decoder(3).pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
